<!-- start of page body -->
<td width="80%" valign="TOP">
  <table width="100%" border="0" cellspacing="2" cellpadding="5">
    <tr><td>
    <TABLE BORDER=0 WIDTH=100% CELLPADDING=0 CELLSPACING=0> <TR> <TD BGCOLOR=#000000 HEIGHT=1><TABLE BORDER=0 WIDTH=100% CELLPADDING=0 CELLSPACING=0><TR><TD></TD></TR></TABLE></TD> </TR> </TABLE>
    <TABLE BORDER=0 WIDTH=100% CELLPADDING=2 CELLSPACING=0>
      <TR><td bgcolor="#EEEED4">
      <b>CMU_ARCTIC speech synthesis databases</b>
      </TD></tr>
    </TABLE>
    <TABLE BORDER=0 WIDTH=100% CELLPADDING=0 CELLSPACING=0> <TR> <TD BGCOLOR=#000000 HEIGHT=1><TABLE BORDER=0 WIDTH=100% CELLPADDING=0 CELLSPACING=0><TR><TD></TD></TR></TABLE></TD> </TR> </TABLE>
    <table width="100%" border="0" cellpadding="10"><tr><td>
    The CMU_ARCTIC databases were constructed at the 
    <A HREF="http://www.lti.cs.cmu.edu/">Language Technologies Institute</A>
    at Carnegie Mellon University as phonetically balanced, US English
    single speaker databases designed for unit selection speech synthesis
    research.
    <P>
    A detailed report on the structure and content of the
    database and the recording environment etc is available as a 
    Carnegie Mellon University, Language Technologies Institute
    Tech Report CMU-LTI-03-177 and is also available 
    <A HREF="cmu_arctic_report.pdf">here</A>.
    <P>
    The databases consist of around 1150 utterances carefully selected
    from out-of-copyright texts from <A
    href="http://promo.net/pg/">Project Gutenberg</A>.  The databses
    include US English male (bdl) and female (slt) speakers (both
    experinced voice talent) as well as other accented speakers.
    </p>
    <p>The 1132 sentence prompt list is available from
    <a href="cmuarctic.data">cmuarctic.data</a>
    </p>
    <p>
    The distributions include 16KHz waveform and simultaneous EGG
    signals.  Full phoentically labelling was perfromed by the
    <A HREF="http://cmusphinx.org">CMU Sphinx</A> using the FestVox
    based labelling scripts.  Complete runnable Festival Voices are
    included with the database distributions, as examples though 
    better voices can be made by improving labelling etc.
    <P>
    <H3>CMU ARCTIC Databases</H3>
    <UL>
    <li><A HREF="dbs_bdl.html">US English bdl (male) (0.95)</A></li>
    <li><A HREF="dbs_slt.html">US English slt (female) (0.95)</A></li>
    <li><A HREF="dbs_clb.html">US English clb (female) (0.95)</A></li>
    <li><A HREF="dbs_rms.html">US English rms (male) (0.95)</A></li>
    </UL>
    <H3>CMU ARCTIC other accents</H3>
    <UL>
    <li><A HREF="dbs_jmk.html">US English jmk by Canadian English male (0.95)</A></li>
    <li><A HREF="dbs_awb.html">US English awb by Scottish English male (0.90)</A></li>
    <li><A HREF="dbs_ksp.html">US English ksp by Indian English male (0.95)</A></li>
    </UL>
    <P>
    These distibutions include Festival CLUNITS based voices.
    bdl, slt, jmk and awb HTS based voices are available from
    available from <A HREF="http://hts.ics.nitech.ac.jp/">
    http://hts.ics.nitech.ac.jp/</A> using Nagoya Institute of Technology's
    HTS HMM-based Speech Synthesis System.
    </P>
    <H3>Acknowledgements</H3>
    <p>
    This work was partially supported by the U.S. National Science
    Foundation under Grant No. 0219687, "ITR/CIS Evaluation and
    Personalization of Synthetic Voices".  Any opinions, findings, and
    conclusions or recommendations expressed in this material are
    those of the authors and do not necessarily reflect the views of
    the National Science Foundation.
    </td></tr></table>
    </td></tr>
  </table>
</td>
